{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "js                   0.392232270276\n",
      "adobe                0.196116135138\n",
      "creative             0.196116135138\n",
      "css                  0.196116135138\n",
      "flask                0.196116135138\n",
      "git                  0.196116135138\n",
      "html                 0.196116135138\n",
      "java                 0.196116135138\n",
      "javascript           0.196116135138\n",
      "mongodb              0.196116135138\n",
      "node                 0.196116135138\n",
      "nosql                0.196116135138\n",
      "python               0.196116135138\n",
      "rdbms                0.196116135138\n",
      "react                0.196116135138\n",
      "regex                0.196116135138\n",
      "scraping             0.196116135138\n",
      "selenium             0.196116135138\n",
      "sql                  0.196116135138\n",
      "suite                0.196116135138\n",
      "Document 0\n",
      "Document 1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import csv\n",
    "\n",
    "with open('linkedin.json') as data_file:    \n",
    "    data = json.load(data_file)\n",
    "df = pd.DataFrame(data)\n",
    "#df.head()\n",
    "\n",
    "#df['_id'] = df['_id'].astype('|S')\n",
    "#df.dtypes\n",
    "#pprint(data)\n",
    "#skills=df['skills'].astype(str)\n",
    "\n",
    "Counter(\" \".join(skills).split(\" \")).items()\n",
    "#[('Someone', 1), ('ft.jgt', 1), ('My', 1), ('is', 2), ('to', 1), ('going', 1), ('place', 1), ('my', 1), ('nickname', 1)]\n",
    "\n",
    "#initialise Vectorisation\n",
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1,1), min_df = 0, stop_words = 'english')\n",
    "\n",
    "#get number of words to analyse creates matix of all words\n",
    "tfidf_matrix =  tf.fit_transform(skills)\n",
    "feature_skills = tf.get_feature_names() \n",
    "print len(feature_skills)\n",
    "\n",
    "#condense matrix to list\n",
    "dense = tfidf_matrix.todense()\n",
    "len(dense[0].tolist()[0])\n",
    "\n",
    "#prints out scores for where word appears\n",
    "linkedin_results = dense[0].tolist()[0]\n",
    "skill_scores = [pair for pair in zip(range(0, len(linkedin_results)), linkedin_results) if pair[1] > 0]\n",
    "\n",
    "len(skill_scores)\n",
    "\n",
    "#lookup for the top 20 scores\n",
    "sorted_skill_scores = sorted(skill_scores, key=lambda t: t[1] * -1)\n",
    "for skill, score in [(feature_skills[word_id], score) for (word_id, score) in sorted_skill_scores][:20]:\n",
    "   print('{0: <20} {1}'.format(skill, score))\n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "with open(\"C:/Users/Kim/Desktop/NISRA_to_share/Data/tfidf_scikit.csv\", \"w\") as file:\n",
    "    writer = csv.writer(file, delimiter=\",\")\n",
    "    writer.writerow([ \"Skill\", \"Score\"])\n",
    "\n",
    "    doc_id = 0\n",
    "    for doc in tfidf_matrix.todense():\n",
    "        print \"Document %d\" %(doc_id)\n",
    "        word_id = 0\n",
    "        for score in doc.tolist()[0]:\n",
    "            if score > 0:\n",
    "                word = feature_skills[word_id]\n",
    "                writer.writerow([doc_id+1, word.encode(\"utf-8\"), score])\n",
    "            word_id +=1\n",
    "        doc_id +=1\n",
    "        \n",
    "#obj = TfidfVectorizer()\n",
    "#X = obj.fit_transform(skills)\n",
    "#print X\n",
    "\n",
    "#print X.__dict__\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
